{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teteumac/ML_Alabama/blob/main/ParticleImages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3DtjEbf8M4I"
      },
      "source": [
        "**Introduction**\n",
        "\n",
        "Machine Learning algorithms have become an increasingly important tool for analyzing the data from the Large Hadron Collider (LHC). Identification of particles in LHC collisions is an important task of LHC detector reconstruction algorithms.\n",
        "\n",
        "Here we present a challenge where one of the detectors (the Electromagnetic Calorimeter or ECAL) is used as a camera to analyze detector images from two types of particles: electrons and photons that deposit their energy in this detector.\n",
        "\n",
        "**Dataset**\n",
        "\n",
        "Each pixel in the image corresponds to a detector cell, while the intensity of the pixel corresponds to how much energy is measured in that cell. Timing of the energy deposits are also available, though this may or may not be relevant. The dataset contains 32x32 Images of the energy hits and their timing (channel 1: hit energy and channel 2: its timing) in each calorimeter cell (one cell = one pixel) for the two classes of particles: Electrons and Photons. The dataset contains around four hundred thousand images for electrons and photons. Please note that your final model will be evaluated on an unseen test dataset.\n",
        "\n",
        "**Algorithm**\n",
        "\n",
        "Please use a Machine Learning model of your choice to achieve the highest possible classification performance on the provided dataset. Please provide a Jupyter Notebook that shows your solution.\n",
        "\n",
        "Evaluation Metrics\n",
        "ROC curve (Receiver Operating Characteristic curve) and AUC score (Area Under the ROC Curve)\n",
        "Training and Validation Accuracy\n",
        "The model performance will be tested on a hidden test dataset based on the above metrics.\n",
        "\n",
        "**Deliverables**\n",
        "\n",
        "Google Colab Jupyter Notebook showing your solution along with the final model accuracy (Training and Validation), ROC curve and AUC score. More details regarding the format of the notebook can be found in the sample Google Colab notebook provided for this challenge.\n",
        "The final trained model including the model architecture and the trained weights ( For example: HDF5 file, .pb file, .pt file, etc. ). You are free to choose Machine Learning Framework of your choice.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ-SHHfw73NF"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/UAPH4582/PH482_582_Sp22/blob/main/Hackathons/Hackathon-02/Hackathon-02.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0b6SRpWl2Xh"
      },
      "source": [
        "## Create the appropriate project folder "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OYRULwKaw_A6"
      },
      "outputs": [],
      "source": [
        "mkdir Particle_Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "at-4-Xub8DYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d67cd8-e891-4436-ea47-f5a471be056a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Particle_Images\n"
          ]
        }
      ],
      "source": [
        "cd Particle_Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BQGKM10j2CiQ"
      },
      "outputs": [],
      "source": [
        "mkdir data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEtRyfNv9XVn"
      },
      "source": [
        "# Download the Dataset\n",
        "This will download 83MB for SingleElectron and 76MB for SinglePhoton."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rcK1wY4Qt_7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9095a32-9e49-4b11-a272-c82743ca5e99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-31 17:19:44--  https://cernbox.cern.ch/index.php/s/sHjzCNFTFxutYCj/download\n",
            "Resolving cernbox.cern.ch (cernbox.cern.ch)... 188.184.97.72, 128.142.53.35, 128.142.170.17, ...\n",
            "Connecting to cernbox.cern.ch (cernbox.cern.ch)|188.184.97.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87010508 (83M) [application/octet-stream]\n",
            "Saving to: ‘data/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5’\n",
            "\n",
            "data/SingleElectron 100%[===================>]  82.98M   108MB/s    in 0.8s    \n",
            "\n",
            "Last-modified header invalid -- time-stamp ignored.\n",
            "2022-03-31 17:19:46 (108 MB/s) - ‘data/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5’ saved [87010508/87010508]\n",
            "\n",
            "--2022-03-31 17:19:46--  https://cernbox.cern.ch/index.php/s/69nGEZjOy3xGxBq/download\n",
            "Resolving cernbox.cern.ch (cernbox.cern.ch)... 188.184.97.72, 128.142.53.35, 128.142.170.17, ...\n",
            "Connecting to cernbox.cern.ch (cernbox.cern.ch)|188.184.97.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 79876391 (76M) [application/octet-stream]\n",
            "Saving to: ‘data/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5’\n",
            "\n",
            "data/SinglePhotonPt 100%[===================>]  76.18M   112MB/s    in 0.7s    \n",
            "\n",
            "Last-modified header invalid -- time-stamp ignored.\n",
            "2022-03-31 17:19:48 (112 MB/s) - ‘data/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5’ saved [79876391/79876391]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#!/bin/bash\n",
        "!wget https://cernbox.cern.ch/index.php/s/sHjzCNFTFxutYCj/download -O data/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\n",
        "!wget https://cernbox.cern.ch/index.php/s/69nGEZjOy3xGxBq/download -O data/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BepRE7pn8Du7"
      },
      "source": [
        "# Import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZnLzC5paz0hb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "import h5py\n",
        "from keras.models import Sequential\n",
        "from keras.initializers import TruncatedNormal\n",
        "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sBTYu-vj5mfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a0fa1d-89d4-4adc-f50f-21ffd48c7158"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az_MoJwZ8K6l"
      },
      "source": [
        "# Keras Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZzF8AHl_4yUA"
      },
      "outputs": [],
      "source": [
        "rate_data   = 0.5\n",
        "lr_init     = 1.e-3    # Initial learning rate  \n",
        "batch_size  = 64       # Training batch size\n",
        "train_size  = int(160000*rate_data)   # Training size, max is 160000\n",
        "valid_size  = int(44800*rate_data)    # Validation size, max is 44800\n",
        "test_size   = 1024     # Test size\n",
        "epochs      = 20       # Number of epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jX_l-WmplJx"
      },
      "source": [
        "It is recommended to use GPU for training and inference if possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwc56kXJ8TLo"
      },
      "source": [
        "# Load Image Data\n",
        "- Two classes of particles: electrons and photons\n",
        "- 32x32 matrices (two channels - hit energy and time) for the two classes of particles electrons and photons impinging on a calorimeter (one calorimetric cell = one pixel).\n",
        "- Note that although timing channel is provided, it may not necessarily help the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kr4QIMlt424u"
      },
      "outputs": [],
      "source": [
        "img_rows, img_cols, nb_channels = 32, 32, 2        \n",
        "input_dir = 'data'\n",
        "decays = ['SinglePhotonPt50_IMGCROPS_n249k_RHv1', 'SingleElectronPt50_IMGCROPS_n249k_RHv1']\n",
        "\n",
        "def load_data(decays, start, stop):\n",
        "    global input_dir\n",
        "    dsets = [h5py.File('%s/%s.hdf5'%(input_dir,decay)) for decay in decays]\n",
        "    X = np.concatenate([dset['/X'][start:stop] for dset in dsets])\n",
        "    y = np.concatenate([dset['/y'][start:stop] for dset in dsets])\n",
        "    assert len(X) == len(y)\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JpHCOf38fDL"
      },
      "source": [
        "# Configure Training / Validation / Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-RTXS58x46Fq"
      },
      "outputs": [],
      "source": [
        "# Set range of training set\n",
        "train_start, train_stop = 0, train_size\n",
        "assert train_stop > train_start\n",
        "assert (len(decays)*train_size) % batch_size == 0\n",
        "X_train, y_train = load_data(decays,train_start,train_stop)\n",
        "\n",
        "# Set range of validation set\n",
        "valid_start, valid_stop = 160000, 160000+valid_size\n",
        "assert valid_stop  >  valid_start\n",
        "assert valid_start >= train_stop\n",
        "X_valid, y_valid = load_data(decays,valid_start,valid_stop)\n",
        "\n",
        "# Set range of test set\n",
        "test_start, test_stop = 204800, 204800+test_size\n",
        "assert test_stop  >  test_start\n",
        "assert test_start >= valid_stop\n",
        "X_test, y_test = load_data(decays,test_start,test_stop)\n",
        "\n",
        "samples_requested = len(decays) * (train_size + valid_size + test_size)\n",
        "samples_available = len(y_train) + len(y_valid) + len(y_test)\n",
        "assert samples_requested == samples_available\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTFIMRnL8w41"
      },
      "source": [
        "# Plot sample of training images\n",
        "Note that although the timing channel is provided, it may not necessarily help the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "e_IDs16U52-C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "ab476ad6-2709-4d31-beca-aa087e8fdac1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(1)\n",
        "\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[1,:,:,0])\n",
        "plt.title(\"Channel 0: Energy\")  # Energy\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1,:,:,1])\n",
        "plt.title(\"Channel 1: Time\")  # Time\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke_NQLiz83jZ"
      },
      "source": [
        "# Define CNN Model\n",
        "This is a sample model. You can experiment with the model and try various architectures and other models to achieve the highest possible performance.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OlIJuxXG7KDk"
      },
      "outputs": [],
      "source": [
        "### Define Convolutional Neural Network (CNN) Model ###\n",
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(hp.Int(\"filters\", 16, 128, step=16), activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal', input_shape=(img_rows, img_cols, nb_channels)))\n",
        "  model.add(Conv2D(hp.Int(\"filters\", 16, 128, step=16), activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(2*hp.Int(\"filters\", 32, 256, step=32), activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal'))\n",
        "  model.add(Conv2D(2*hp.Int(\"filters\", 32, 256, step=32), activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(keras.layers.BatchNormalization())\n",
        "  model.add(Dense(units=2*hp.Int(\"units\", 128, 512, step=32), activation='relu', kernel_initializer='TruncatedNormal'))\n",
        "  #if hp.Boolean(\"dropout\"):\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(keras.layers.BatchNormalization())\n",
        "  model.add(Dense(units=hp.Int(\"units\", 128, 512, step=32), activation='relu', kernel_initializer='TruncatedNormal'))\n",
        "  #if hp.Boolean(\"dropout\"):\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(1, activation='sigmoid', kernel_initializer='TruncatedNormal'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal', input_shape=(img_rows, img_cols, nb_channels)))\n",
        "model.add(Conv2D(16, activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal'))\n",
        "model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu', kernel_initializer='TruncatedNormal'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu', kernel_initializer='TruncatedNormal'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='sigmoid', kernel_initializer='TruncatedNormal'))\n",
        "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "model.summary()'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "LBJlBPKydE2W",
        "outputId": "33f960b0-3245-4810-dae6-8f48eb8f6d57"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmodel = Sequential()\\nmodel.add(Conv2D(16, activation=\\'relu\\', kernel_size=3, padding=\\'same\\', kernel_initializer=\\'TruncatedNormal\\', input_shape=(img_rows, img_cols, nb_channels)))\\nmodel.add(Conv2D(16, activation=\\'relu\\', kernel_size=3, padding=\\'same\\', kernel_initializer=\\'TruncatedNormal\\'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\nmodel.add(Conv2D(32, activation=\\'relu\\', kernel_size=3, padding=\\'same\\', kernel_initializer=\\'TruncatedNormal\\'))\\nmodel.add(Conv2D(32, activation=\\'relu\\', kernel_size=3, padding=\\'same\\', kernel_initializer=\\'TruncatedNormal\\'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\nmodel.add(Flatten())\\nmodel.add(Dense(1024, activation=\\'relu\\', kernel_initializer=\\'TruncatedNormal\\'))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(512, activation=\\'relu\\', kernel_initializer=\\'TruncatedNormal\\'))\\nmodel.add(Dropout(0.25))\\nmodel.add(Dense(1, activation=\\'sigmoid\\', kernel_initializer=\\'TruncatedNormal\\'))\\nmodel.compile(loss=\\'binary_crossentropy\\', optimizer=\"adam\", metrics=[\\'accuracy\\'])\\nmodel.summary()'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the `HyperParameters` and set the values.\n",
        "!pip install -q -U keras-tuner\n",
        "import keras_tuner as kt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "hp = kt.HyperParameters()\n",
        "model = build_model(hp)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-1vmaS8BugZ",
        "outputId": "43841805-23e8-44b0-9c96-03e49b2ed959"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 40 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 51 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 61 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 71 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 81 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 92 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 102 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 112 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 122 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 133 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133 kB 12.6 MB/s \n",
            "\u001b[?25hModel: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 16)        304       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 16)        2320      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 2048)             8192      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               524544    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 583,297\n",
            "Trainable params: 578,689\n",
            "Non-trainable params: 4,608\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    max_trials=15,\n",
        "    # Do not resume the previous search in the same directory.\n",
        "    overwrite=True,\n",
        "    objective=\"val_accuracy\",\n",
        "    # Set a directory to store the intermediate results.\n",
        "    directory=\"/tmp/tb\",\n",
        ")\n",
        "'''\n",
        "history=model.fit(X_train, y_train,\\\n",
        "        batch_size=batch_size,\\\n",
        "        epochs=epochs,\\\n",
        "        validation_data=(X_valid, y_valid),\\\n",
        "        verbose=1, shuffle=True)\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MlONP9cZB2XW",
        "outputId": "1aa791a5-21dd-4534-a655-fb10357f5049"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nhistory=model.fit(X_train, y_train,        batch_size=batch_size,        epochs=epochs,        validation_data=(X_valid, y_valid),        verbose=1, shuffle=True)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(\n",
        "    X_train,\n",
        "    y_train,shuffle=True,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    epochs=2,\n",
        "    # Use the TensorBoard callback.\n",
        "    # The logs will be write to \"/tmp/tb_logs\".\n",
        "    callbacks=[keras.callbacks.TensorBoard(\"/tmp/tb_logs\")],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "440hKlTZB6EW",
        "outputId": "ac3e010c-f266-461a-8c36-06e7b40fac33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 07m 24s]\n",
            "val_accuracy: 0.5033705234527588\n",
            "\n",
            "Best val_accuracy So Far: 0.6856138110160828\n",
            "Total elapsed time: 03h 03m 00s\n",
            "\n",
            "Search: Running Trial #21\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "64                |16                |filters\n",
            "512               |128               |units\n",
            "\n",
            "Epoch 1/2\n",
            "    5/10000 [..............................] - ETA: 4:41 - loss: 0.8727 - accuracy: 0.5125WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0069s vs `on_train_batch_end` time: 0.0226s). Check your callbacks.\n",
            "10000/10000 [==============================] - 256s 25ms/step - loss: 0.6181 - accuracy: 0.6673 - val_loss: 7.0850 - val_accuracy: 0.5000\n",
            "Epoch 2/2\n",
            " 1343/10000 [===>..........................] - ETA: 3:25 - loss: 0.5888 - accuracy: 0.6972"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "S9pKdR4cCTIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsQWFD0M86pA"
      },
      "source": [
        "## Train the Model\n",
        "You may further optimize the model, tune hyper-parameters, etc. accordingly to achieve the best performance possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGuyM25L7uc0"
      },
      "outputs": [],
      "source": [
        "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1.e-6)\n",
        "\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history=model.fit(X_train, y_train,\\\n",
        "        batch_size=batch_size,\\\n",
        "        epochs=epochs,\\\n",
        "        validation_data=(X_valid, y_valid),\\\n",
        "        verbose=1, shuffle=True)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(X_train, y_train, epochs=best_epoch, batch_size=batch_size, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "Yn4D3xVFCsfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLoN43278_-j"
      },
      "source": [
        "## Evaluate the Model  \n",
        "Along with the model accuracy, the prefered metric for evaluation is ROC (Receiver Operating Characteristic) curve and the AUC score (Area under the ROC Curve)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekuQLYas7xh5"
      },
      "outputs": [],
      "source": [
        "# Evaluate on validation set\n",
        "score = hypermodel.evaluate(X_valid, y_valid, verbose=1)\n",
        "print('\\nValidation loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
        "y_pred = hypermodel.predict(X_valid)\n",
        "fpr, tpr, _ = roc_curve(y_valid, y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print('Validation ROC AUC:', roc_auc)\n",
        "\n",
        "# Evaluate on test set\n",
        "score = hypermodel.evaluate(X_test, y_test, verbose=1)\n",
        "print('\\nTest loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
        "y_pred = hypermodel.predict(X_test)\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print('Test ROC AUC:', roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmSRYI0R72Wn"
      },
      "outputs": [],
      "source": [
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "#plt.legend(loc=2, prop={'size': 15})\n",
        "plt.plot(fpr, tpr, label='Model 1 (ROC-AUC = {:.3f})'.format(roc_auc))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nna7GkM45Y5w"
      },
      "source": [
        "# Submission format: \n",
        "Submit the Google Colab Jupyter Notebook demonstrating your solution in the similar format as illustrated in this notebook. It should contain:\n",
        "*   The final model architecture, parameters and hyper-parameters yielding the best possible performance,\n",
        "*   Its Training and Validation accuracy, \n",
        "*   ROC curve and the AUC score as shown above.\n",
        "*   Also, please submit the final trained model containing the model architecture and its trained weights along with this notebook (For example: HDF5 file, .pb file, .pt file, etc.). Either in this notebook or in a separate notebook show how to load and use your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tph19i6Z5mfk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the training model Neural Network in .h5 file "
      ],
      "metadata": {
        "id": "7DRnOuMk78oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "prefixy_NN = \"output_NeuralNetwork\"\n",
        "with h5py.File( prefixy_NN +'.h5', 'w') as f:\n",
        "   dset = f.create_dataset( 'NN', data = hypermodel )"
      ],
      "metadata": {
        "id": "JhulhQno7TBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open .h5 file"
      ],
      "metadata": {
        "id": "O_FpMg4J8FdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def open_file( path_file ):\n",
        "    with h5py.File( path_file , 'r' ) as f:\n",
        "        model_training_NN = f['NN']\n",
        "        return model_training_NN"
      ],
      "metadata": {
        "id": "5dhFebuf8IOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BzlCCSDy_XJa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ParticleImages.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}